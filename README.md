# 人工智能与机器学习 MO平台小作业
## 1. 内容介绍
本仓库包括MO平台的四个小作业。大作业项目中的黑白棋、垃圾分类等在其他仓库中有相关参考资料，本人也是借鉴了那些资料，因此这里不再展示。四个文件夹内容分别包括：
- 双相障碍检测：训练模型代码`train.py`、模型预测代码与提交代码`main.py`、实验报告markdown文件
- 机器人自动走迷宫：路径搜索代码`path_search.py`、DQNRobot模型训练代码`DQNRobot.py`、提交的代码`main.py`、实验报告markdown文件
- 口罩佩戴检测：模型训练代码`train.py`、模型预测代码`predict.py`、修改后的新的库函数文件`MobileNetV2.py`、`FaceRec2.py`、实验报告markdown文件
- 作家风格识别：训练模型代码`train.py`、模型预测代码`predict.py`、提交代码`main.py`、实验报告markdown文件

以上所有程序，仅保证在作者电脑上测试的结果，不保证在各位的电脑上测试结果相同。**模型的训练本身即存在随机性。**

对于口罩佩戴检测的Lab，本人经过与同学的慎重考虑，决定不提供模型文件，以免大规模抄袭问题。毕竟还是得自己的模型自己练，不然实验报告莫得写。

**小彩蛋：** 本仓库中同时提供了文件格式转换程序`transfer.py`，可在实验报告撰写时使用。该程序可以将下载的`.ipynb`文件转化为`Markdown`格式文件，使用时注意文件路径与文件名修改好即可。当然，其他希望实现的功能可以让AI写一段python代码实现。

**注意：该文件转换格式生成的markdown文件中不包含cell中代码的运行结果，不包含cell中部分非网络图片，需要后续手动加入。**

## 2. MO平台使用方法与特点：
这里只针对该课程的作业，其他MO平台功能不做解释。
### 2.1 创建、重置新Lab
实验平台会在打开作业的同时创建完整项目架构，包括实验指导，实验必要数据集和相应的文件。在实验中途若由于代码混乱需要重置为初始状态，可在页面右上角找到重置功能（这里一共有两个按键，具体可以根据名称对应）。若希望保存当前实验内容，建议提前保存重要文件。

在实训作业页面，点击Lab名称可在当前页面下拉弹出项目内容与具体的**评分标准** （这里的评分标准仅为Lab实验结果的分数，实验报告的分数由助教确定），供参考。
### 2.2 实验指导与程序编写/运行
这里主要使用了给出的`.ipynb`格式文件，该文件中给明了具体Lab的实验内容与预先的样例代码。实验内容与样例夹杂，建议不要过多修改（当然你保证能撤回另算）。实验作业提交的代码部分均会有特殊文字提示，且相应的代码块（`.ipynb`文件中叫做cell）会以注释的形式给出提醒，自己编写的代码提交到指定cell中即可。

在指定cell中完成程序，包括样例程序，可选中该cell，页面左上角点击 **“Run”** ，可选择运行所有cell或当前选中cell。这里几点额外说明：

- 当前cell运行模式：有时会报错，可能原因是未导入python库文件。建议将必要的`import`操作（主要是实验指导开始时的“导入必要的库”部分的代码）复制到当前cell中再运行该cell，或从最开始的cell不断逐个运行。程序具有一定的记忆机制，无额外操作时会记忆之前运行过的cell。
- 所有cell运行模式：执行所有的cell中的代码，连贯且按序运行，若无中途点击cell导致中断，则前面执行的代码后续会有所记忆，可有效规避只运行当前cell模式的问题。但有时样例代码运行时间过久，需要一定权衡考虑是否执行该种运行模式。
### 2.3 模型训练与作业提交
这里是最需要注意的一部分，项目中会给出一个通用的作业提交指南，但一些细节仍然需要额外强调：

- **模型训练是必要的：** 机器学习部分的Lab大多需要训练一定的模型，这些必须在测试前预先运行代码获得相应的模型文件，否则Lab会因为检测不到加载的文件而报错。
- `main.py`函数生成：提交作业第一步需要生成相应函数，这里建议不做大修改。修改内容直接到`.ipynb`文件中进行。
- 测试与提交：测试不通过不可提交，**提交作业只有一次机会** ，且需要上传`程序报告.docx`或`程序报告.pdf`，注意这里文件名和后缀名都不能有一丁点的改动，否则系统检测不到不能提交。若不小心提交失误，请迅速找老师或助教帮你撤回作业。

在模型训练过程中，部分Lab模型训练时间非常长（如可能训练一个小时，或者CPU训练会崩溃等），此时建议使用平台提供的2小时免费GPU使用时间进行GPU训练，会成百倍地加快运行速度，使用方式如下：

- 点击文件页面最上方一栏中间的GPU芯片图标，创建任务。文件名一般以原文件名+.py显示，例如在`123.ipynb`文件中创建，则该GPU任务执行的文件名则为`123.py`。
- 创建的任务默认会将该`.ipynb`文件中所有代码按顺序写入，我们需要手动删除不需要的部分，仅保留模型训练部分（有时可以增加模型预测部分以做效果检验）。
- 创建任务后上边栏的图标数会减少，此时找到并点击运行功能，会弹出窗口，选择使用GPU，并在右边选择相关需要一同执行的文件（一般来说直接全选即可），可见任务创建，左侧任务栏窗口有所显示。任务名可在前面弹出的窗口中自定义设置，否则采用随机值。
- 模型的GPU任务需要一定的启动时间，开始执行后可以在任务栏对应任务上，找到`显示日志`，可观察日志输出，日志的开头和结尾均为GPU任务自带的系统信息，中间为程序输出结果。另外，平台给出了可视化的功能使用，可适当尝试，可视化可利于实验报告分析，但并不是必须的。
- GPU任务可能会报错终止，此时需要检查相应的代码是否正确。GPU免费使用总时长有一定限制，会在页面最下方以及使用GPU的选项后给出。
### 2.4 文件保存与下载
MO平台提供了文件拷贝副本、下载、删除、重命名功能。若你希望保存一个当前较好的模型，或者希望保存当前的任务代码，建议留好备份。同时平台支持上传文件。

**注意：文件的下载只能逐个文件下载，平台不支持文件夹下载。**

## 3. 项目的各个注意事项：
### 3.1 双相障碍检测
这一部分的代码大多数都是照抄实验指导内容的代码并拼贴结合，因此整体难度不大，调参也相对简单。

这部分最主要的参数是特征数`select_feature_number`，这里需要注意的要点是该参数要随时跟随测试结果中的报错适当调整main函数内容。在本仓库的代码中，模型训练部分的参数设置为`12`，但main函数中的参数设置为`10`（在作者提交的过程中发现，如果后者也是12，则会报错显示特征数不匹配）。不同的电脑中结果可能不同，要随着报错提示微调`main.py`以及相应源代码中的参数。

另外，虽然双模态特征选择与融合方法更为合理，但实际若使用该方法选取特征会极大增加特征数，在后续测试中会出现报错信息（报错显示的特征数会很大），因此作者不建议在实际的模型训练部分使用这种方法。当然如果能正确执行的话效果应该会更合理。
### 3.2 机器人自动走迷宫
这部分难度并不大，分为两个小Lab——搜索算法、DQN算法。

在搜索算法部分，基本思路为copy给出的样例代码（广度优先算法）中的模型类函数，修改其中的路径搜索部分。相关提及的路径搜索算法都易于理解和编写，本仓库的项目中使用了深度优先搜索，这种方法在原代码的基础上改动最小，而例如A*算法则是广度优先搜索算法的改进，大家后续可以多多尝试，这一部分还是简单的。

第二个程序为DQN算法，整体思路较为简单。相互借鉴的效果基本稳定。
### 3.3 口罩佩戴检测
这部分是四个Lab中最为折磨的一个，需要使用指定方法进行人脸识别，并训练模型进行口罩检测。其中人脸识别的样例很简单，机器学习主要应用于口罩检测。但也发现一些问题并希望给大家提一些建议：

- 平台给出了多个`.ipynb`文件，如`torch_main.py`等，选择其一执行即可。不同的`.ipynb`文件保存与加载的模型后缀名不同，配套且在程序中需要导入的库文件也不同，测试与提交时只需要使用对应的文件即可。
- 由于需要读取图像数据并进行卷积，该模型的训练需要耗费巨大的时间，当`epcho = 20`时接近需要一个小时，运行中途可发现CPU占用巨高，且经常程序崩溃并训练中断，**建议训练模型直接使用GPU** 。
- 人脸识别结果欠佳。本身这个是实验指导的问题，如果你在测试中发现人脸识别结果不好的话，建议选择其他方法修改给出的其他库文件。
- 模型随机性。在我的测试中发现，同一段代码连续三次训练的模型效果各异，若你认为结果并不好，建议多训练几次，并记得保留好最佳文件。
### 3.4 作家风格识别
整体较为舒适的一个实验，按照指导一步步操作即可，包括分词、模型设置、训练与预测等。在此Lab的模型训练中发现，每个人针对同一段代码的模型效果不同，建议根据个人结果适当调参。实验代码中的部分功能，如分词模式、损失函数等，具有多种方法，可相互替代但结果不同，可相互测试查找最佳的调用函数。

本仓库中的代码利用了一段新的模型定义代码，与实验指导中的不同，使用时需要注意。若出现相应报错可以咨询AI。

### 3.5 平台测试得分
- 双相障碍检测：三项概率均为1.0（大部分网络资源基本都能达到这个成绩）。
- 机器人自动走迷宫：均完成迷宫。
- 口罩佩戴检测：大部分代码一般能达到90/100以上，极少数模型可满分。本仓库的程序曾经产生一个满分模型，不保证移植后效果一致。
- 作家风格识别：49/50，在原作者（下文链接）中实现了满分，但我这里只有48/50。

## 4. 相关参考代码链接如下：
作者在完成实验的过程中也参考了一些前人的结果，将展示如下：

- [https://github.com/Y-vic/ZJU_AI_ML_Lab/tree/master](https://github.com/Y-vic/ZJU_AI_ML_Lab/tree/master)
- [基于Python实现的作家风格识别](https://blog.csdn.net/newlw/article/details/124949923)

